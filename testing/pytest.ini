[tool:pytest]
# Pytest Configuration for Enhanced Cognee Testing

# Test Discovery
testpaths = testing
python_files = test_*.py *_test.py
python_classes = Test*
python_functions = test_*

# Output and Reporting
addopts =
    --strict-markers
    --strict-config
    --verbose
    --tb=short
    --cov=../cognee
    --cov=../src
    --cov-report=html:reports/coverage/html
    --cov-report=xml:reports/coverage/coverage.xml
    --cov-report=term-missing
    --cov-fail-under=95
    --html=reports/pytest/report.html
    --self-contained-html
    --json-report
    --json-report-file=reports/pytest/report.json
    --benchmark-only
    --benchmark-sort=mean
    --benchmark-json=reports/benchmark/benchmark.json

# Markers for Test Categories
markers =
    # Test Categories
    unit: Unit tests for individual components
    integration: Integration tests for component interaction
    system: End-to-end system tests
    uat: User acceptance tests
    performance: Performance and load tests
    security: Security vulnerability tests
    automation: Test automation validation
    contracts: API and protocol contract tests
    chaos: Chaos engineering and resilience tests
    compliance: Regulatory compliance tests

    # Component Categories
    memory: Memory stack related tests
    agents: Agent system tests
    coordination: Multi-agent coordination tests
    api: API endpoint tests
    database: Database related tests
    infrastructure: Infrastructure and deployment tests

    # Performance Categories
    load: Load testing scenarios
    stress: Stress testing scenarios
    endurance: Endurance testing scenarios
    scalability: Scalability testing scenarios

    # Security Categories
    vulnerability: Vulnerability assessment tests
    penetration: Penetration testing scenarios
    authentication: Authentication and authorization tests
    encryption: Data encryption and protection tests

    # Scenario Categories
    business: Business workflow scenarios
    technical: Technical failure scenarios
    mixed: Mixed complex scenarios

    # Priority Levels
    critical: Critical path tests that must pass
    high: High priority tests
    medium: Medium priority tests
    low: Low priority tests

    # Execution Speed
    fast: Fast running tests (<1 second)
    medium: Medium running tests (1-10 seconds)
    slow: Slow running tests (>10 seconds)

    # Environment Requirements
    requires_docker: Tests requiring Docker infrastructure
    requires_database: Tests requiring database setup
    requires_internet: Tests requiring internet connectivity
    requires_large_memory: Tests requiring significant memory

    # Data Requirements
    requires_test_data: Tests requiring specific test data
    generates_test_data: Tests that generate test data
    cleanup_required: Tests requiring cleanup after execution

# Minimum Version
minversion = 7.4.3

# Logging
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Async Configuration
asyncio_mode = auto

# Timeout Configuration
timeout = 300  # 5 minutes default timeout
timeout_method = thread

# Parallel Execution
# -n auto for automatic CPU detection
# Use: pytest -n auto

# Filtering
# Run specific categories: pytest -m "unit or integration"
# Exclude slow tests: pytest -m "not slow"
# Run only critical tests: pytest -m "critical"

# Environment Variables
env =
    TESTING=true
    ENHANCED_COGNEE_ENV=test
    DATABASE_URL=postgresql://test:test@localhost:25432/test_cognee
    QDRANT_URL=http://localhost:26333
    NEO4J_URL=bolt://localhost:27474
    REDIS_URL=redis://localhost:26379

# Custom Configuration Files
# Use: pytest -c custom_pytest.ini

# Benchmark Configuration
[tool:pytest-benchmark]
min_rounds = 5
max_time = 60
min_time = 1
histogram = true
save_data = true
json_file = reports/benchmark/benchmark.json

# Coverage Configuration
[coverage:run]
source = ../cognee,../src
omit =
    */tests/*
    */test_*
    */__pycache__/*
    */migrations/*
    */venv/*
    */env/*
    */.tox/*

[coverage:report]
exclude_lines =
    pragma: no cover
    def __repr__
    if self.debug:
    if settings.DEBUG
    raise AssertionError
    raise NotImplementedError
    if 0:
    if __name__ == .__main__.:
    class .*\(Protocol\):
    @(abc\.)?abstractmethod

show_missing = True
precision = 2

[coverage:html]
directory = reports/coverage/html

[coverage:xml]
output = reports/coverage/coverage.xml

# Logging Configuration
[loggers]
keys = root, cognee, testing

[handlers]
keys = console, file

[formatters]
keys = generic

[logger_root]
level = INFO
handlers = console, file

[logger_cognee]
level = INFO
handlers = console, file
propagate = 0
qualname = cognee

[logger_testing]
level = DEBUG
handlers = console, file
propagate = 0
qualname = testing

[handler_console]
class = StreamHandler
level = INFO
formatter = generic
args = (sys.stdout,)

[handler_file]
class = FileHandler
level = DEBUG
formatter = generic
args = ('reports/testing.log', 'a')

[formatter_generic]
format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s
datefmt = %Y-%m-%d %H:%M:%S