# Enhanced Cognee Implementation Guide

## üìã Table of Contents

1. [Overview](#overview)
2. [Architecture](#architecture)
3. [Installation](#installation)
4. [Configuration](#configuration)
5. [Enhanced Memory Stack](#enhanced-memory-stack)
6. [Agent System](#agent-system)
7. [Integration](#integration)
8. [Examples](#examples)
9. [Troubleshooting](#troubleshooting)

## üéØ Overview

Enhanced Cognee is an enterprise-grade memory architecture that extends the original Cognee system with:

- **Enhanced Memory Stack**: PostgreSQL+pgVector, Qdrant, Neo4j, Redis
- **21-Agent Integration**: ATS/OMA/SMC categorized agent system
- **Advanced Coordination**: Task orchestration and distributed decision making
- **Production Monitoring**: Grafana + Prometheus dashboards
- **Zero-Cost Infrastructure**: Docker Swarm instead of Kubernetes

## üèóÔ∏è Architecture

### Memory Stack Components

```mermaid
graph TB
    A[Enhanced Cognee] --> B[PostgreSQL+pgVector]
    A --> C[Qdrant Vector DB]
    A --> D[Neo4j Graph DB]
    A --> E[Redis Cache]

    B --> F[Structured Data]
    C --> G[Vector Similarity]
    D --> H[Relationship Graph]
    E --> I[High-Speed Caching]
```

### Agent Categories

```mermaid
graph LR
    A[Enhanced Cognee] --> B[ATS - 7 Agents]
    A --> C[OMA - 10 Agents]
    A --> D[SMC - 6 Agents]

    B --> E[Trading System]
    C --> F[Development System]
    D --> G[Coordination System]
```

## üöÄ Installation

### Prerequisites
- Docker and Docker Compose
- Python 3.9+
- Docker Swarm (optional but recommended)

### Quick Start

```bash
# Clone or navigate to the project
cd C:\Users\Vincent_Pereira\Projects\AI Agents\enhanced-cognee

# Start Enhanced stack
docker-compose -f docker/docker-compose-enhanced-cognee.yml up -d

# Verify services
docker-compose -f docker/docker-compose-enhanced-cognee.yml ps
```

## ‚öôÔ∏è Configuration

### Environment Variables

Create `.env` file:

```bash
# Database Configuration
POSTGRES_PASSWORD=cognee_password
QDRANT_API_KEY=your_qdrant_api_key
NEO4J_PASSWORD=neo4j_password
REDIS_PASSWORD=redis_password

# Enhanced Cognee Configuration
ENHANCED_COGNEE_PORT=28080
LOG_LEVEL=INFO
MEMORY_RETENTION_DAYS=30

# Agent Configuration
ENABLE_AUTO_COORDINATION=true
AGENT_DISCOVERY_INTERVAL=60
```

### Docker Compose Configuration

```yaml
version: '3.8'

services:
  enhanced-cognee:
    build:
      context: .
      dockerfile: docker/Dockerfile.enhanced-cognee
    environment:
      - POSTGRES_HOST=postgres
      - QDRANT_HOST=qdrant
      - NEO4J_HOST=neo4j
      - REDIS_HOST=redis
    ports:
      - "28080:8000"
    depends_on:
      - postgres
      - qdrant
      - neo4j
      - redis
    networks:
      - cognee-network
```

## üóÑÔ∏è Enhanced Memory Stack

### PostgreSQL+pgVector Setup

```python
import asyncpg
from pgvector.asyncpg import register_vector

async def setup_postgres():
    conn = await asyncpg.connect(
        host="localhost",
        port=25432,
        database="cognee_db",
        user="cognee_user",
        password="cognee_password"
    )

    await register_vector(conn)
    await conn.execute("""
        CREATE EXTENSION IF NOT EXISTS vector;
        CREATE TABLE IF NOT EXISTS memories (
            id SERIAL PRIMARY KEY,
            content TEXT,
            embedding vector(1536),
            metadata JSONB,
            created_at TIMESTAMP DEFAULT NOW()
        );
    """)
```

### Qdrant Vector Database

```python
from qdrant_client import QdrantClient
from qdrant_client.models import VectorParams, Distance

async def setup_qdrant():
    client = QdrantClient(host="localhost", port=6333)

    # Create collection
    await client.create_collection(
        collection_name="memories",
        vectors_config=VectorParams(size=1536, distance=Distance.COSINE)
    )
```

### Neo4j Graph Database

```python
from neo4j import GraphDatabase

async def setup_neo4j():
    driver = GraphDatabase.driver(
        "bolt://localhost:7687",
        auth=("neo4j", "password")
    )

    with driver.session() as session:
        session.run("""
            CREATE CONSTRAINT IF NOT EXISTS FOR (m:Memory) REQUIRE m.id IS UNIQUE
            CREATE INDEX IF NOT EXISTS FOR (m:Memory) ON (m.content)
        """)
```

## ü§ñ Agent System

### Agent Registry

```python
from agent_memory_integration import AgentMemoryIntegration, MemoryCategory

# Initialize agent system
agent_system = AgentMemoryIntegration()

# Check available agents
print(f"Total agents: {len(agent_system.agent_registry)}")

# ATS Agents (Algorithmic Trading System)
ats_agents = [agent_id for agent_id, info in agent_system.agent_registry.items()
               if info['category'] == MemoryCategory.ATS]

# OMA Agents (Other Multi-Agent)
oma_agents = [agent_id for agent_id, info in agent_system.agent_registry.items()
               if info['category'] == MemoryCategory.OMA]

# SMC Agents (Shared Multi-Agent Components)
smc_agents = [agent_id for agent_id, info in agent_system.agent_registry.items()
               if info['category'] == MemoryCategory.SMC]
```

### Using Agents

```python
from src.agents.ats import AlgorithmicTradingSystem
from src.agents.oma import CodeReviewer
from src.agents.smc import ContextManager

# Initialize agents
trading_agent = AlgorithmicTradingSystem()
code_reviewer = CodeReviewer()
context_manager = ContextManager()

# Store agent memory
await agent_system.add_memory(
    agent_id="algorithmic-trading-system",
    content="BTC price analysis showing upward trend",
    memory_type="episodic",
    metadata={
        "symbol": "BTC/USD",
        "confidence": 0.85,
        "timestamp": "2025-11-12T23:00:00Z"
    }
)
```

## üîÑ Integration Patterns

### 1. MCP Integration

```python
from enhanced_cognee_mcp import EnhancedCogneeMCPServer

# Initialize MCP server
mcp_server = EnhancedCogneeMCPServer()

# Store memory via MCP
memory_id = await mcp_server.add_memory(
    content="Trading signal detected for ETH",
    agent_id="algorithmic-trading-system",
    memory_category="ats",
    metadata={"symbol": "ETH/USD", "confidence": 0.92}
)
```

### 2. REST API Integration

```python
import requests

# Store memory via API
response = requests.post("http://localhost:28080/api/v1/memory", json={
    "content": "Code review completed for security module",
    "agent_id": "code-reviewer",
    "memory_category": "oma",
    "metadata": {"file": "security.py", "status": "completed"}
})

# Search memory
search_results = requests.get("http://localhost:28080/api/v1/memory/search", params={
    "query": "security module",
    "agent_id": "code-reviewer"
})
```

### 3. Direct Python Integration

```python
from src.coordination.sub_agent_coordinator import SubAgentCoordinator
from agent_memory_integration import AgentMemoryIntegration

# Initialize coordination
memory_integration = AgentMemoryIntegration()
coordinator = SubAgentCoordinator(memory_integration)

# Create coordination task
task = {
    "task_id": "code-review-001",
    "title": "Review security implementation",
    "description": "Review authentication and authorization code",
    "assigned_to": ["code-reviewer", "security-auditor"],
    "priority": "high"
}

await coordinator.assign_task(task)
```

## üìö Examples

### Example 1: Trading Agent Memory Management

```python
# examples/trading_agent_memory.py
import asyncio
from agent_memory_integration import AgentMemoryIntegration
from src.agents.ats import AlgorithmicTradingSystem

async def trading_memory_example():
    # Initialize systems
    memory_integration = AgentMemoryIntegration()
    trading_agent = AlgorithmicTradingSystem()

    # Store trading signal
    signal_data = {
        "symbol": "BTC/USD",
        "signal_type": "buy",
        "confidence": 0.87,
        "price": 45000.0,
        "volume": 125000000,
        "timestamp": "2025-11-12T15:30:00Z"
    }

    await memory_integration.add_memory(
        agent_id="algorithmic-trading-system",
        content=f"Buy signal for {signal_data['symbol']} at ${signal_data['price']}",
        memory_type="episodic",
        metadata=signal_data
    )

    # Search for similar signals
    results = await memory_integration.search_memory(
        agent_id="algorithmic-trading-system",
        query="BTC trading signals",
        limit=10
    )

    print(f"Found {len(results)} related signals")
    return results

# Run example
if __name__ == "__main__":
    asyncio.run(trading_memory_example())
```

### Example 2: Multi-Agent Coordination

```python
# examples/multi_agent_coordination.py
import asyncio
from src.coordination.task_orchestration import TaskOrchestrationEngine
from src.coordination.distributed_decision import DistributedDecisionMaker

async def coordination_example():
    # Initialize coordination systems
    memory_integration = AgentMemoryIntegration()
    orchestrator = TaskOrchestrationEngine(memory_integration)
    decision_maker = DistributedDecisionMaker()

    # Create complex task
    task_definition = {
        "task_id": "security-audit-001",
        "title": "Complete Security Audit",
        "description": "Perform comprehensive security audit of trading system",
        "assigned_to": [
            "security-auditor",
            "code-reviewer",
            "compliance-monitor"
        ],
        "dependencies": [],
        "priority": "critical",
        "estimated_duration": "2 hours"
    }

    # Coordinate task execution
    result = await orchestrator.execute_workflow(task_definition)

    # Create decision proposal
    proposal = await decision_maker.create_proposal(
        decision_type="risk_assessment",
        title="Trading System Risk Level",
        description="Assess overall system risk based on audit results",
        options=["Low Risk", "Medium Risk", "High Risk", "Critical Risk"],
        voting_deadline="2025-11-12T16:00:00Z"
    )

    print(f"Task result: {result}")
    print(f"Decision proposal created: {proposal['proposal_id']}")

    return result, proposal
```

### Example 3: Memory Integration Testing

```python
# examples/memory_integration_test.py
import asyncio
from agent_memory_integration import AgentMemoryIntegration, MemoryCategory, MemoryType

async def test_memory_integration():
    """Test all agent categories and memory types"""
    memory_integration = await AgentMemoryIntegration.initialize()

    test_data = [
        {
            "agent_id": "algorithmic-trading-system",
            "category": MemoryCategory.ATS,
            "content": "Market volatility detected in cryptocurrency market",
            "memory_type": MemoryType.EPISODIC,
            "metadata": {"market": "crypto", "volatility": "high"}
        },
        {
            "agent_id": "code-reviewer",
            "category": MemoryCategory.OMA,
            "content": "Refactored authentication module with improved security",
            "memory_type": MemoryType.PROCEDURAL,
            "metadata": {"file": "auth.py", "lines_changed": 150}
        },
        {
            "agent_id": "context-manager",
            "category": MemoryCategory.SMC,
            "content": "Session context established for trading dashboard",
            "memory_type": MemoryType.SEMANTIC,
            "metadata": {"session_id": "sess_001", "dashboard": "trading"}
        }
    ]

    results = []
    for data in test_data:
        try:
            memory_id = await memory_integration.add_memory(**data)
            results.append({"status": "success", "memory_id": memory_id, **data})
        except Exception as e:
            results.append({"status": "error", "error": str(e), **data})

    # Test search functionality
    search_results = await memory_integration.search_memory(
        query="security authentication",
        agent_id="code-reviewer",
        limit=5
    )

    return results, search_results
```

### Example 4: Docker Deployment

```bash
# examples/docker_deployment.sh
#!/bin/bash

# Enhanced Cognee Docker Deployment Script

echo "Starting Enhanced Cognee Deployment..."

# Create networks
docker network create cognee-network --driver overlay
docker network create monitoring-network --driver overlay

# Start Enhanced Stack
docker-compose -f docker/docker-compose-enhanced-cognee.yml up -d

# Wait for services to be ready
echo "Waiting for services to initialize..."
sleep 30

# Start Monitoring Stack
docker-compose -f docker/docker-compose-monitoring.yml up -d

echo "Deployment Complete!"
echo "Enhanced Cognee: http://localhost:28080"
echo "Grafana Dashboard: http://localhost:3000"
echo "Prometheus: http://localhost:9090"
```

## üîß Troubleshooting

### Common Issues

#### 1. Database Connection Issues

```python
# Check database connectivity
async def test_database_connections():
    try:
        # Test PostgreSQL
        conn = await asyncpg.connect(
            "postgresql://cognee_user:cognee_password@localhost:25432/cognee_db"
        )
        print("‚úÖ PostgreSQL connection successful")
        await conn.close()

        # Test Qdrant
        client = QdrantClient(host="localhost", port=26333)
        collections = await client.get_collections()
        print(f"‚úÖ Qdrant connection successful. Collections: {len(collections)}")

        # Test Neo4j
        driver = GraphDatabase.driver("bolt://localhost:7687", auth=("neo4j", "password"))
        driver.verify_connectivity()
        print("‚úÖ Neo4j connection successful")
        driver.close()

        # Test Redis
        import redis
        r = redis.Redis(host="localhost", port=26379)
        r.ping()
        print("‚úÖ Redis connection successful")

    except Exception as e:
        print(f"‚ùå Database connection failed: {e}")
```

#### 2. Agent Memory Issues

```python
# Debug agent memory
async def debug_agent_memory():
    memory_integration = AgentMemoryIntegration()

    # Check agent registry
    print(f"Total registered agents: {len(memory_integration.agent_registry)}")

    for agent_id, info in memory_integration.agent_registry.items():
        category = info.get('category', 'unknown')
        prefix = info.get('prefix', '')
        print(f"Agent: {agent_id} | Category: {category} | Prefix: {prefix}")

    # Test memory storage
    try:
        test_memory_id = await memory_integration.add_memory(
            agent_id="algorithmic-trading-system",
            content="Test memory",
            memory_type="test"
        )
        print(f"‚úÖ Memory storage successful. ID: {test_memory_id}")
    except Exception as e:
        print(f"‚ùå Memory storage failed: {e}")
```

#### 3. Docker Issues

```bash
# Check container status
docker-compose -f docker/docker-compose-enhanced-cognee.yml ps

# View logs
docker-compose -f docker/docker-compose-enhanced-cognee.yml logs enhanced-cognee

# Restart services
docker-compose -f docker/docker-compose-enhanced-cognee.yml restart

# Clean up
docker-compose -f docker/docker-compose-enhanced-cognee.yml down -v
```

### Performance Optimization

#### Memory Usage Optimization

```python
# Configure memory retention and cleanup
async def configure_memory_optimization():
    memory_integration = AgentMemoryIntegration()

    # Set retention policies
    memory_retention = {
        MemoryType.EPISODIC: 30,  # days
        MemoryType.PROCEDURAL: 90,
        MemoryType.SEMANTIC: 180,
        MemoryType.FACTUAL: 365
    }

    for memory_type, days in memory_retention.items():
        await memory_integration.configure_retention(
            memory_type=memory_type,
            retention_days=days
        )
```

## üìä Monitoring

### Key Metrics

1. **Memory Storage**: Total memories stored per agent category
2. **Query Performance**: Search response times
3. **Agent Activity**: Active vs inactive agents
4. **System Health**: Database connectivity and performance
5. **Resource Usage**: CPU, memory, disk utilization

### Grafana Dashboards

- **Enhanced Cognee Overview**: System-wide metrics
- **Agent Performance**: Individual agent metrics
- **Memory Analytics**: Storage and query statistics
- **Infrastructure Health**: Component health monitoring

---

*Last Updated: 2025-11-12*
*Enhanced Cognee Implementation Guide*