"""
Ecosystem Development Framework
Implements API marketplace, community features, and third-party integrations
"""

import os
import json
import time
import asyncio
import logging
import hashlib
from typing import Dict, List, Any, Optional, Tuple, Union
from dataclasses import dataclass, asdict, field
from enum import Enum
from datetime import datetime, timezone, timedelta
from pathlib import Path
import uuid
import base64
import requests

import aiohttp
import aiofiles
import yaml
import jinja2
from packaging import version
from dataclasses_json import dataclass_json
import markdown
import feedparser

logger = logging.getLogger(__name__)


class IntegrationType(Enum):
    """Integration types"""
    WEBHOOK = "webhook"
    REST_API = "rest_api"
    GRAPHQL = "graphql"
    MESSAGE_QUEUE = "message_queue"
    DATABASE = "database"
    FILE_STORAGE = "file_storage"
    AUTHENTICATION = "authentication"
    MONITORING = "monitoring"
    NOTIFICATION = "notification"
    CUSTOM = "custom"


class PluginType(Enum):
    """Plugin types"""
    AGENT_EXTENSION = "agent_extension"
    DATA_SOURCE = "data_source"
    VISUALIZATION = "visualization"
    AUTOMATION = "automation"
    ANALYTICS = "analytics"
    SECURITY = "security"
    COMMUNICATION = "communication"
    UTILITY = "utility"


class MarketplaceCategory(Enum):
    """Marketplace categories"""
    AGENTS = "agents"
    INTEGRATIONS = "integrations"
    PLUGINS = "plugins"
    TEMPLATES = "templates"
    TOOLS = "tools"
    DATASETS = "datasets"
    MODELS = "models"
    DOCUMENTATION = "documentation"


@dataclass
class MarketplaceItem:
    """Marketplace item (integration, plugin, etc.)"""
    item_id: str
    name: str
    description: str
    category: MarketplaceCategory
    subcategory: str
    version: str
    author: str
    author_id: str
    rating: float
    download_count: int
    created_at: datetime
    updated_at: datetime
    tags: List[str] = field(default_factory=list)
    requirements: List[str] = field(default_factory=list)
    compatibility: List[str] = field(default_factory=list)
    license_type: str = "MIT"
    pricing_model: str = "free"  # free, paid, freemium, enterprise
    file_url: str = ""
    documentation_url: str = ""
    repository_url: str = ""
    changelog: str = ""
    is_featured: bool = False
    is_verified: bool = False
    support_info: Dict[str, Any] = field(default_factory=dict)


@dataclass
class Plugin:
    """Plugin definition"""
    plugin_id: str
    name: str
    description: str
    plugin_type: PluginType
    version: str
    entry_point: str
    configuration_schema: Dict[str, Any]
    dependencies: List[str]
    permissions: List[str]
    metadata: Dict[str, Any] = field(default_factory=dict)
    created_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    updated_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))


@dataclass
class Integration:
    """Third-party integration"""
    integration_id: str
    name: str
    description: str
    integration_type: IntegrationType
    version: str
    configuration_schema: Dict[str, Any]
    authentication: Dict[str, Any]
    endpoints: Dict[str, str]
    rate_limits: Dict[str, int] = field(default_factory=dict)
    webhook_urls: List[str] = field(default_factory=list)
    status: str = "active"
    created_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    updated_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))


@dataclass
class CommunityContributor:
    """Community contributor"""
    contributor_id: str
    username: str
    email: str
    bio: str
    avatar_url: str
    github_username: str
    contributions: List[str] = field(default_factory=list)
    join_date: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    reputation: int = 0
    badges: List[str] = field(default_factory=list)


@dataclass
class Issue:
    """Community issue or discussion"""
    issue_id: str
    title: str
    description: str
    category: str
    status: str  # open, in_progress, resolved, closed
    priority: str
    author_id: str
    assignee_id: str
    created_at: datetime
    updated_at: datetime
    tags: List[str] = field(default_factory=list)
    comments: List[Dict[str, Any]] = field(default_factory=list)
    attachments: List[str] = field(default_factory=list)


class APIKey:
    """API key for third-party access"""
    key_id: str
    key_hash: str
    user_id: str
    permissions: List[str]
    rate_limit: int
    expires_at: Optional[datetime]
    created_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    last_used: Optional[datetime] = None


class MarketplaceManager:
    """Manages the API marketplace and ecosystem"""

    def __init__(self, storage_path: str = "./marketplace_data"):
        self.storage_path = Path(storage_path)
        self.storage_path.mkdir(parents=True, exist_ok=True)

        self.marketplace_items: Dict[str, MarketplaceItem] = {}
        self.plugins: Dict[str, Plugin] = {}
        self.integrations: Dict[str, Integration] = {}
        self.contributors: Dict[str, CommunityContributor] = {}
        self.issues: Dict[str, Issue] = {}
        self.api_keys: Dict[str, APIKey] = {}

        # Load existing data
        self._load_data()

    def _load_data(self):
        """Load existing marketplace data"""
        try:
            # Load marketplace items
            items_file = self.storage_path / "marketplace_items.json"
            if items_file.exists():
                with open(items_file, 'r') as f:
                    items_data = json.load(f)
                    for item_data in items_data:
                        item = MarketplaceItem(**item_data)
                        self.marketplace_items[item.item_id] = item

            # Load plugins
            plugins_file = self.storage_path / "plugins.json"
            if plugins_file.exists():
                with open(plugins_file, 'r') as f:
                    plugins_data = json.load(f)
                    for plugin_data in plugins_data:
                        plugin = Plugin(**plugin_data)
                        plugin.created_at = datetime.fromisoformat(plugin.created_at)
                        plugin.updated_at = datetime.fromisoformat(plugin.updated_at)
                        self.plugins[plugin.plugin_id] = plugin

            logger.info(f"Loaded {len(self.marketplace_items)} marketplace items, {len(self.plugins)} plugins")

        except Exception as e:
            logger.warning(f"Failed to load marketplace data: {e}")

    def _save_data(self):
        """Save marketplace data to disk"""
        try:
            # Save marketplace items
            items_file = self.storage_path / "marketplace_items.json"
            items_data = []
            for item in self.marketplace_items.values():
                item_data = asdict(item)
                item_data['created_at'] = item.created_at.isoformat()
                item_data['updated_at'] = item.updated_at.isoformat()
                items_data.append(item_data)

            with open(items_file, 'w') as f:
                json.dump(items_data, f, indent=2)

            # Save plugins
            plugins_file = self.storage_path / "plugins.json"
            plugins_data = []
            for plugin in self.plugins.values():
                plugin_data = asdict(plugin)
                plugin_data['created_at'] = plugin.created_at.isoformat()
                plugin_data['updated_at'] = plugin.updated_at.isoformat()
                plugins_data.append(plugin_data)

            with open(plugins_file, 'w') as f:
                json.dump(plugins_data, f, indent=2)

            logger.info("Saved marketplace data to disk")

        except Exception as e:
            logger.error(f"Failed to save marketplace data: {e}")

    async def register_marketplace_item(
        self,
        name: str,
        description: str,
        category: MarketplaceCategory,
        version: str,
        author: str,
        author_id: str,
        tags: List[str] = None,
        requirements: List[str] = None,
        file_content: bytes = None,
        license_type: str = "MIT",
        pricing_model: str = "free"
    ) -> MarketplaceItem:
        """Register a new item in the marketplace"""
        logger.info(f"Registering marketplace item: {name}")

        item_id = str(uuid.uuid4())

        # Create marketplace item
        item = MarketplaceItem(
            item_id=item_id,
            name=name,
            description=description,
            category=category,
            subcategory=category.value,
            version=version,
            author=author,
            author_id=author_id,
            rating=0.0,
            download_count=0,
            created_at=datetime.now(timezone.utc),
            updated_at=datetime.now(timezone.utc),
            tags=tags or [],
            requirements=requirements or [],
            compatibility=["enhanced_cognee"],  # Default compatibility
            license_type=license_type,
            pricing_model=pricing_model
        )

        # Save file if provided
        if file_content:
            file_path = self.storage_path / "files" / category.value
            file_path.mkdir(parents=True, exist_ok=True)
            file_name = f"{item_id}_{name.replace(' ', '_')}.zip"
            full_path = file_path / file_name

            async with aiofiles.open(full_path, 'wb') as f:
                await f.write(file_content)
            item.file_url = f"/marketplace/files/{category.value}/{file_name}"

        # Store item
        self.marketplace_items[item_id] = item
        self._save_data()

        logger.info(f"Marketplace item {name} registered successfully")
        return item

    async def search_marketplace_items(
        self,
        query: str = None,
        category: MarketplaceCategory = None,
        tags: List[str] = None,
        featured_only: bool = False,
        verified_only: bool = False,
        limit: int = 20
    -> List[MarketplaceItem]:
        """Search marketplace items"""
        all_items = list(self.marketplace_items.values())

        # Filter items
        filtered_items = []
        for item in all_items:
            # Category filter
            if category and item.category != category:
                continue

            # Featured filter
            if featured_only and not item.is_featured:
                continue

            # Verified filter
            if verified_only and not item.is_verified:
                continue

            # Tag filter
            if tags and not any(tag in item.tags for tag in tags):
                continue

            # Text search
            if query:
                search_text = query.lower()
                item_text = f"{item.name} {item.description} {' '.join(item.tags)}".lower()
                if search_text not in item_text:
                    continue

            filtered_items.append(item)

        # Sort by rating and download count
        filtered_items.sort(
            key=lambda x: (x.rating, x.download_count),
            reverse=True
        )

        return filtered_items[:limit]

    async def get_marketplace_item(self, item_id: str) -> Optional[MarketplaceItem]:
        """Get marketplace item by ID"""
        return self.marketplace_items.get(item_id)

    async def update_download_count(self, item_id: str):
        """Update download count for marketplace item"""
        item = self.marketplace_items.get(item_id)
        if item:
            item.download_count += 1
            item.updated_at = datetime.now(timezone.utc)
            self._save_data()
            logger.info(f"Updated download count for item {item_id}")

    async def rate_item(self, item_id: str, user_id: str, rating: int, review: str = "") -> bool:
        """Rate a marketplace item"""
        item = self.marketplace_items.get(item_id)
        if not item:
            return False

        # Validate rating
        if rating < 1 or rating > 5:
            return False

        # Update item rating (simplified - in production, store detailed reviews)
        # For demo, just update overall rating
        old_rating = item.rating
        item.rating = (old_rating + rating) / 2  # Simple average
        item.updated_at = datetime.now(timezone.utc)

        self._save_data()
        logger.info(f"Rated item {item_id} with {rating} stars by user {user_id}")
        return True


class PluginManager:
    """Manages plugins and extensions"""

    def __init__(self, storage_path: str = "./plugins"):
        self.storage_path = Path(storage_path)
        self.storage_path.mkdir(parents=True, exist_ok=True)

        self.installed_plugins: Dict[str, Plugin] = {}
        self.active_plugins: Dict[str, Any] = {}  # Runtime instances
        self.plugin_registry: Dict[str, Dict[str, Any]] = {}

        self._load_plugins()

    def _load_plugins(self):
        """Load installed plugins"""
        plugins_dir = self.storage_path / "installed"
        if plugins_dir.exists():
            for plugin_dir in plugins_dir.iterdir():
                if plugin_dir.is_dir():
                    manifest_path = plugin_dir / "plugin.json"
                    if manifest_path.exists():
                        try:
                            with open(manifest_path, 'r') as f:
                                manifest = json.load(f)
                            plugin = Plugin(**manifest)
                            plugin.created_at = datetime.fromisoformat(plugin.created_at)
                            plugin.updated_at = datetime.fromisoformat(plugin.updated_at)
                            self.installed_plugins[plugin.plugin_id] = plugin
                            logger.info(f"Loaded plugin: {plugin.name}")
                        except Exception as e:
                            logger.error(f"Failed to load plugin from {plugin_dir}: {e}")

    async def install_plugin(self, plugin_file_path: str) -> bool:
        """Install a plugin from file"""
        try:
            # Extract plugin
            plugin_dir = await self._extract_plugin(plugin_file_path)

            # Load plugin manifest
            manifest_path = plugin_dir / "plugin.json"
            with open(manifest_path, 'r') as f:
                manifest = json.load(f)

            plugin = Plugin(**manifest)
            plugin.created_at = datetime.now(timezone.utc)
            plugin.updated_at = datetime.now(timezone.utc)

            # Validate plugin
            if await self._validate_plugin(plugin):
                # Store plugin
                self.installed_plugins[plugin.plugin_id] = plugin
                logger.info(f"Installed plugin: {plugin.name} (ID: {plugin.plugin_id})")
                return True

        except Exception as e:
            logger.error(f"Failed to install plugin from {plugin_file_path}: {e}")
            return False

        return False

    async def _extract_plugin(self, plugin_file_path: str) -> Path:
        """Extract plugin ZIP file"""
        import zipfile

        # Create plugins directory if it doesn't exist
        plugins_dir = self.storage_path / "installed"
        plugins_dir.mkdir(parents=True, exist_ok=True)

        # Extract plugin
        with zipfile.ZipFile(plugin_file_path, 'r') as zip_ref:
            plugin_id = str(uuid.uuid4())
            extract_dir = plugins_dir / plugin_id
            zip_ref.extractall(extract_dir)

            return extract_dir

    async def _validate_plugin(self, plugin: Plugin) -> bool:
        """Validate plugin configuration"""
        # Check required fields
        if not all([plugin.name, plugin.plugin_type, plugin.version, plugin.entry_point]):
            return False

        # Check entry point exists
        plugin_dir = self.storage_path / "installed" / plugin.plugin_id
        entry_point_path = plugin_dir / plugin.entry_point
        if not entry_point_path.exists():
            logger.error(f"Entry point not found: {plugin.entry_point}")
            return False

        return True

    async def load_plugin(self, plugin_id: str) -> bool:
        """Load and initialize a plugin"""
        plugin = self.installed_plugins.get(plugin_id)
        if not plugin:
            return False

        try:
            # Import plugin module
            plugin_dir = self.storage_path / "installed" / plugin_id
            sys.path.insert(0, str(plugin_dir))

            # Load the plugin
            spec = importlib.util.spec_from_file_location(
                plugin.entry_point.replace('.py', ''),
                str(plugin_dir / plugin.entry_point)
            )
            module = importlib.util.module_from_spec(spec)

            # Initialize plugin
            if hasattr(module, 'initialize'):
                instance = module.initialize()
                self.active_plugins[plugin_id] = instance

                logger.info(f"Loaded plugin: {plugin.name}")
                return True

        except Exception as e:
            logger.error(f"Failed to load plugin {plugin_id}: {e}")
            return False

    async def unload_plugin(self, plugin_id: str) -> bool:
        """Unload a plugin"""
        if plugin_id in self.active_plugins:
            try:
                # Call cleanup if available
                instance = self.active_plugins[plugin_id]
                if hasattr(instance, 'cleanup'):
                    await instance.cleanup()

                del self.active_plugins[plugin_id]
                logger.info(f"Unloaded plugin: {plugin_id}")
                return True

            except Exception as e:
                logger.error(f"Failed to unload plugin {plugin_id}: {e}")

        return False

    async def list_plugins(self, plugin_type: PluginType = None) -> List[Plugin]:
        """List installed plugins"""
        plugins = list(self.installed_plugins.values())
        if plugin_type:
            plugins = [p for p in plugins if p.plugin_type == plugin_type]
        return plugins

    async def get_plugin_info(self, plugin_id: str) -> Optional[Dict[str, Any]]:
        """Get plugin information"""
        plugin = self.installed_plugins.get(plugin_id)
        if not plugin:
            return None

        info = asdict(plugin)
        info['is_active'] = plugin_id in self.active_plugins

        return info


class CommunityManager:
    """Manages community features and contributions"""

    def __init__(self, storage_path: str = "./community"):
        self.storage_path = Path(storage_path)
        self.storage_path.mkdir(parents=True, exist_ok=True)

        self.contributors: Dict[str, CommunityContributor] = {}
        self.issues: Dict[str, Issue] = {}
        self.forum_posts: List[Dict[str, Any]] = []
        self.discussions: List[Dict[str, Any]] = []

        self._load_community_data()

    def _load_community_data(self):
        """Load community data"""
        try:
            # Load contributors
            contributors_file = self.storage_path / "contributors.json"
            if contributors_file.exists():
                with open(contributors_file, 'r') as f:
                    contributors_data = json.load(f)
                    for contributor_data in contributors_data:
                        contributor = CommunityContributor(**contributor_data)
                        contributor.join_date = datetime.fromisoformat(contributor.join_date)
                        self.contributors[contributor.contributor_id] = contributor

            logger.info(f"Loaded {len(self.contributors)} community contributors")

        except Exception as e:
            logger.warning(f"Failed to load community data: {e}")

    def _save_community_data(self):
        """Save community data to disk"""
        try:
            # Save contributors
            contributors_file = self.storage_path / "contributors.json"
            contributors_data = []
            for contributor in self.contributors.values():
                contributor_data = asdict(contributor)
                contributor_data['join_date'] = contributor.join_date.isoformat()
                contributors_data.append(contributor_data)

            with open(contributors_file, 'w') as f:
                json.dump(contributors_data, f, indent=2)

            logger.info("Saved community data to disk")

        except Exception as e:
            logger.error(f"Failed to save community data: {e}")

    async def register_contributor(
        self,
        username: str,
        email: str,
        bio: str = "",
        avatar_url: str = "",
        github_username: str = ""
    ) -> CommunityContributor:
        """Register a new community contributor"""
        contributor_id = str(uuid.uuid4())

        contributor = CommunityContributor(
            contributor_id=contributor_id,
            username=username,
            email=email,
            bio=bio,
            avatar_url=avatar_url,
            github_username=github_username,
            contributions=[],
            join_date=datetime.now(timezone.utc),
            reputation=0,
            badges=["newbie"]
        )

        self.contributors[contributor_id] = contributor
        self._save_community_data()

        logger.info(f"Registered community contributor: {username}")
        return contributor

    async def create_issue(
        self,
        title: str,
        description: str,
        category: str,
        priority: str,
        author_id: str,
        tags: List[str] = None
    ) -> Issue:
        """Create a community issue"""
        issue_id = str(uuid.uuid4())

        issue = Issue(
            issue_id=issue_id,
            title=title,
            description=description,
            category=category,
            status="open",
            priority=priority,
            author_id=author_id,
            assignee_id="",
            created_at=datetime.now(timezone.utc),
            updated_at=datetime.now(timezone.utc),
            tags=tags or [],
            comments=[],
            attachments=[]
        )

        self.issues[issue_id] = issue
        self._save_community_data()

        # Notify community about new issue
        await self._notify_new_issue(issue)

        logger.info(f"Created community issue: {title}")
        return issue

    async def _notify_new_issue(self, issue: Issue):
        """Notify community about new issue"""
        # In production, this would send notifications
        logger.info(f"New issue created: {issue.title} by {issue.author_id}")

    async def search_issues(
        self,
        query: str = None,
        category: str = None,
        status: str = None,
        author_id: str = None,
        limit: int = 20
    ) -> List[Issue]:
        """Search community issues"""
        all_issues = list(self.issues.values())

        # Filter issues
        filtered_issues = []
        for issue in all_issues:
            # Category filter
            if category and issue.category != category:
                continue

            # Status filter
            if status and issue.status != status:
                continue

            # Author filter
            if author_id and issue.author_id != author_id:
                continue

            # Text search
            if query:
                search_text = query.lower()
                issue_text = f"{issue.title} {issue.description} {' '.join(issue.tags)}".lower()
                if search_text not in issue_text:
                    continue

            filtered_issues.append(issue)

        # Sort by creation date (newest first)
        filtered_issues.sort(key=lambda x: x.created_at, reverse=True)

        return filtered_issues[:limit]

    async def add_comment(
        self,
        issue_id: str,
        author_id: str,
        content: str,
        attachments: List[str] = None
    ) -> bool:
        """Add comment to issue"""
        issue = self.issues.get(issue_id)
        if not issue:
            return False

        comment = {
            "comment_id": str(uuid.uuid4()),
            "author_id": author_id,
            "content": content,
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "attachments": attachments or []
        }

        issue.comments.append(comment)
        issue.updated_at = datetime.now(timezone.utc)
        self._save_community_data()

        logger.info(f"Added comment to issue {issue_id}")
        return True

    async def get_contributor_stats(self, contributor_id: str) -> Dict[str, Any]:
        """Get contributor statistics"""
        contributor = self.contributors.get(contributor_id)
        if not contributor:
            return {"error": "Contributor not found"}

        # Calculate statistics
        user_issues = [issue for issue in self.issues.values() if issue.author_id == contributor_id]
        total_issues = len(user_issues)
        resolved_issues = len([issue for issue in user_issues if issue.status == "resolved"])
        open_issues = total_issues - resolved_issues

        return {
            "contributor_id": contributor_id,
            "username": contributor.username,
            "reputation": contributor.reputation,
            "badges": contributor.badges,
            "join_date": contributor.join_date.isoformat(),
            "issues_created": total_issues,
            "issues_resolved": resolved_issues,
            "issues_open": open_issues,
            "contributions": len(contributor.contributions),
            "github_username": contributor.github_username
        }


class IntegrationManager:
    """Manages third-party integrations"""

    def __init__(self, storage_path: str = "./integrations"):
        self.storage_path = Path(storage_path)
        self.storage_path.mkdir(parents=True, exist_ok=True)

        self.integrations: Dict[str, Integration] = {}
        self.active_integrations: Dict[str, Any] = {}
        self.webhook_endpoints: Dict[str, str] = {}

        self._load_integrations()

    def _load_integrations(self):
        """Load existing integrations"""
        try:
            integrations_file = self.storage_path / "integrations.json"
            if integrations_file.exists():
                with open(integrations_file, 'r') as f:
                    integrations_data = json.load(f)
                    for integration_data in integrations_data:
                        integration = Integration(**integration_data)
                        integration.created_at = datetime.fromisoformat(integration.created_at)
                        integration.updated_at = datetime.fromisoformat(integration.updated_at)
                        self.integrations[integration.integration_id] = integration

            logger.info(f"Loaded {len(self.integrations)} integrations")

        except Exception as e:
            logger.warning(f"Failed to load integrations: {e}")

    def _save_integrations(self):
        """Save integrations to disk"""
        try:
            integrations_file = self.storage_path / "integrations.json"
            integrations_data = []
            for integration in self.integrations.values():
                integration_data = asdict(integration)
                integration_data['created_at'] = integration.created_at.isoformat()
                integration_data['updated_at'] = integration.updated_at.isoformat()
                integrations_data.append(integration_data)

            with open(integrations_file, 'w') as f:
                json.dump(integrations_data, f, indent=2)

            logger.info("Saved integrations to disk")

        except Exception as e:
            logger.error(f"Failed to save integrations: {e}")

    async def register_integration(
        self,
        name: str,
        description: str,
        integration_type: IntegrationType,
        version: str,
        configuration_schema: Dict[str, Any],
        authentication: Dict[str, Any] = None,
        endpoints: Dict[str, str] = None
    ) -> Integration:
        """Register a new integration"""
        integration_id = str(uuid.uuid4())

        integration = Integration(
            integration_id=integration_id,
            name=name,
            description=description,
            integration_type=integration_type,
            version=version,
            configuration_schema=configuration_schema,
            authentication=authentication or {},
            endpoints=endpoints or {},
            status="active",
            created_at=datetime.now(timezone.utc),
            updated_at=datetime.now(timezone.utc)
        )

        self.integrations[integration_id] = integration
        self._save_integrations()

        logger.info(f"Registered integration: {name}")
        return integration

    async def configure_integration(
        self,
        integration_id: str,
        configuration: Dict[str, Any]
    ) -> bool:
        """Configure an integration"""
        integration = self.integrations.get(integration_id)
        if not integration:
            return False

        try:
            # Validate configuration against schema
            if integration.configuration_schema:
                self._validate_configuration(
                    configuration,
                    integration.configuration_schema
                )

            # Store configuration
            integration.configuration = configuration
            integration.updated_at = datetime.now(timezone.utc)

            self.integrations[integration_id] = integration
            self._save_integrations()

            logger.info(f"Configured integration: {integration.name}")
            return True

        except Exception as e:
            logger.error(f"Failed to configure integration {integration_id}: {e}")
            return False

    def _validate_configuration(self, config: Dict[str, Any], schema: Dict[str, Any]):
        """Validate configuration against schema"""
        # Simplified validation
        required_fields = schema.get("required", [])
        for field in required_fields:
            if field not in config:
                raise ValueError(f"Required field missing: {field}")

        # Validate field types
        field_types = schema.get("properties", {})
        for field, field_config in field_types.items():
            if field in config:
                expected_type = field_config.get("type")
                actual_value = config[field]

                if expected_type == "string" and not isinstance(actual_value, str):
                    raise ValueError(f"Field {field} must be a string")
                elif expected_type == "integer" and not isinstance(actual_value, int):
                    raise ValueError(f"Field {field} must be an integer")
                elif expected_type == "boolean" and not isinstance(actual_value, bool):
                    raise ValueError(f"Field {field} must be a boolean")

    async def test_integration(self, integration_id: str) -> Dict[str, Any]:
        """Test integration connectivity"""
        integration = self.integrations.get(integration_id)
        if not integration:
            return {"success": False, "error": "Integration not found"}

        test_result = {
            "integration_id": integration_id,
            "integration_name": integration.name,
            "test_timestamp": datetime.now(timezone.utc).isoformat(),
            "tests": []
        }

        try:
            # Test endpoints
            for endpoint_name, endpoint_url in integration.endpoints.items():
                try:
                    async with aiohttp.ClientSession() as session:
                        async with session.get(endpoint_url, timeout=aiohttp.ClientTimeout(total=10)) as response:
                            if response.status == 200:
                                test_result["tests"].append({
                                    "endpoint": endpoint_name,
                                    "url": endpoint_url,
                                    "status": "success",
                                    "status_code": response.status,
                                    "response_time_ms": response.headers.get("X-Response-Time", 0)
                                })
                            else:
                                test_result["tests"].append({
                                    "endpoint": endpoint_name,
                                    "url": endpoint_url,
                                    "status": "error",
                                    "status_code": response.status,
                                    "error": f"HTTP {response.status}"
                                })
                except Exception as e:
                    test_result["tests"].append({
                        "endpoint": endpoint_name,
                        "url": endpoint_url,
                        "status": "error",
                        "error": str(e)
                    })

            # Overall test result
            test_result["success"] = all(
                test.get("status") == "success" for test in test_result["tests"]
            )

        except Exception as e:
            test_result["success"] = False
            test_result["error"] = str(e)

        return test_result

    async def create_webhook_endpoint(self, integration_id: str) -> str:
        """Create webhook endpoint for integration"""
        webhook_id = str(uuid.uuid4())
        webhook_url = f"/webhooks/{webhook_id}"

        self.webhook_endpoints[webhook_id] = integration_id

        # Store webhook in integration
        integration = self.integrations.get(integration_id)
        if integration:
            if not integration.webhook_urls:
                integration.webhook_urls = []
            integration.webhook_urls.append(webhook_url)
            integration.updated_at = datetime.now(timezone.utc)
            self._save_integrations()

        logger.info(f"Created webhook endpoint {webhook_url} for integration {integration_id}")
        return webhook_url


class APIKeyManager:
    """Manages API keys for third-party access"""

    def __init__(self, storage_path: str = "./api_keys"):
        self.storage_path = Path(storage_path)
        self.storage_path.mkdir(parents=True, exist_ok=True)

        self.api_keys: Dict[str, APIKey] = {}
        self.api_key_cache: Dict[str, APIKey] = {}

    async def create_api_key(
        self,
        user_id: str,
        permissions: List[str],
        rate_limit: int = 1000,
        expires_days: int = None
    ) -> APIKey:
        """Create a new API key"""
        key_id = str(uuid.uuid4())
        api_key_string = str(uuid.uuid4())

        # Hash the API key for storage
        key_hash = hashlib.sha256(api_key_string.encode()).hexdigest()

        expires_at = None
        if expires_days:
            expires_at = datetime.now(timezone.utc) + timedelta(days=expires_days)

        api_key = APIKey(
            key_id=key_id,
            key_hash=key_hash,
            user_id=user_id,
            permissions=permissions,
            rate_limit=rate_limit,
            expires_at=expires_at,
            created_at=datetime.now(timezone.utc)
        )

        self.api_keys[key_hash] = api_key
        self.api_key_cache[api_key_string] = api_key

        logger.info(f"Created API key for user {user_id}")
        return api_key

    async def validate_api_key(self, api_key_string: str, required_permission: str = None) -> Optional[APIKey]:
        """Validate API key"""
        key_hash = hashlib.sha256(api_key_string.encode()).hexdigest()

        api_key = self.api_keys.get(key_hash)
        if not api_key:
            return None

        # Check expiration
        if api_key.expires_at and api_key.expires_at < datetime.now(timezone.utc):
            return None

        # Check permissions
        if required_permission and required_permission not in api_key.permissions:
            return None

        # Update last used time
        api_key.last_used = datetime.now(timezone.utc)

        return api_key

    async def revoke_api_key(self, api_key_hash: str) -> bool:
        """Revoke an API key"""
        if api_key_hash in self.api_keys:
            del self.api_keys[api_key_hash]
            # Also remove from cache if present
            # (In production, implement proper cache invalidation)
            logger.info("API key revoked")
            return True

        return False


class EcosystemManager:
    """Main ecosystem management orchestrator"""

    def __init__(
        self,
        marketplace_path: str = "./marketplace",
        plugins_path: str = "./plugins",
        community_path: str = "./community",
        integrations_path: str = "./integrations",
        api_keys_path: str = "./api_keys"
    ):
        self.marketplace_manager = MarketplaceManager(marketplace_path)
        self.plugin_manager = PluginManager(plugins_path)
        self.community_manager = CommunityManager(community_path)
        self.integration_manager = IntegrationManager(integrations_path)
        self.api_key_manager = APIKeyManager(api_keys_path)

        self.ecosystem_stats = {
            "total_marketplace_items": 0,
            "total_plugins": 0,
            "total_integrations": 0,
            "total_contributors": 0,
            "total_issues": 0,
            "active_api_keys": 0
        }

    async def get_ecosystem_overview(self) -> Dict[str, Any]:
        """Get comprehensive ecosystem overview"""
        self._update_stats()

        overview = {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "statistics": self.ecosystem_stats,
            "marketplace": {
                "total_items": len(self.marketplace_manager.marketplace_items),
                "categories": {
                    category.value: len([item for item in self.marketplace_manager.marketplace_items.values() if item.category == category])
                    for category in MarketplaceCategory
                },
                "featured_items": len([item for item in self.marketplace_manager.total_items.values() if item.is_featured]),
                "verified_items": len([item for item in self.marketplace_manager.total_items.values() if item.is_verified])
            },
            "plugins": {
                "total_installed": len(self.plugin_manager.installed_plugins),
                "active_plugins": len(self.plugin_manager.active_plugins),
                "types": {
                    plugin_type.value: len([p for p in self.plugin_manager.installed_plugins.values() if p.plugin_type == plugin_type])
                    for plugin_type in PluginType
                }
            },
            "community": {
                "total_contributors": len(self.community_manager.contributors),
                "total_issues": len(self.community_manager.issues),
                "open_issues": len([issue for issue in self.community_manager.issues.values() if issue.status == "open"]),
                "resolved_issues": len([issue for issue in self.community_manager.issues.values() if issue.status == "resolved"])
            },
            "integrations": {
                "total": len(self.integration_manager.integrations),
                "active": len([i for i in self.integration_manager.integrations.values() if i.status == "active"]),
                "types": {
                    integration_type.value: len([i for i in self.integration_manager.integrations.values() if i.integration_type == integration_type])
                    for integration_type in IntegrationType
                }
            },
            "api_keys": {
                "total": len(self.api_key_manager.api_keys),
                "active": len([k for k in self.api_key_manager.api_keys.values() if not k.expires_at or k.expires_at > datetime.now(timezone.utc)])
            }
        }

        return overview

    def _update_stats(self):
        """Update ecosystem statistics"""
        self.ecosystem_stats = {
            "total_marketplace_items": len(self.marketplace_manager.marketplace_items),
            "total_plugins": len(self.plugin_manager.installed_plugins),
            "total_integrations": len(self.integration_manager.integrations),
            "total_contributors": len(self.community_manager.contributors),
            "total_issues": len(self.community_manager.issues),
            "active_api_keys": len([k for k in self.api_key_manager.api_keys.values() if not k.expires_at or k.expires_at > datetime.now(timezone.utc)])
        }


# Pytest test fixtures and tests
@pytest.fixture
async def ecosystem_manager():
    """Ecosystem manager fixture"""
    return EcosystemManager()


@pytest.fixture
def sample_marketplace_items():
    """Sample marketplace items fixture"""
    return [
        {
            "name": "Advanced Trading Strategy Plugin",
            "description": "Sophisticated trading algorithms with machine learning",
            "category": MarketplaceCategory.PLUGINS,
            "version": "2.1.0",
            "author": "Quant Labs",
            "author_id": "user_001",
            "tags": ["trading", "ml", "algorithms"],
            "pricing_model": "freemium"
        },
        {
            "name": "Slack Integration",
            "description": "Connect Enhanced Cognee with Slack for real-time notifications",
            "category": MarketplaceCategory.INTEGRATIONS,
            "version": "1.0.0",
            "author": "Integration Masters",
            "author_id": "user_002",
            "tags": ["slack", "notifications", "messaging"],
            "pricing_model": "paid"
        },
        {
            "name": "Real-Time Dashboard",
            "description": "Interactive dashboard for monitoring agent performance",
            "category": MarketplaceCategory.VISUALIZATION,
            "version": "3.0.0",
            "author": "DataVis Co",
            "author_id": "user_003",
            "tags": ["dashboard", "monitoring", "analytics"],
            "pricing_model": "freemium"
        }
    ]


@pytest.mark.ecosystem
async def test_marketplace_registration(ecosystem_manager, sample_marketplace_items):
    """Test marketplace item registration"""
    for item_data in sample_marketplace_items:
        # Convert to file content for demo
        file_content = b"Mock file content for marketplace item"

        item = await ecosystem_manager.marketplace_manager.register_marketplace_item(
            name=item_data["name"],
            description=item_data["description"],
            category=item_data["category"],
            version=item_data["version"],
            author=item_data["author"],
            author_id=item_data["author_id"],
            tags=item_data["tags"],
            file_content=file_content,
            pricing_model=item_data["pricing_model"]
        )

        assert item.item_id is not None, "Item should have an ID"
        assert item.name == item_data["name"], "Name should match"
        assert item.category == item_data["category"], "Category should match"
        assert item.author == item_data["author"], "Author should match"
        assert len(item.tags) > 0, "Tags should be set"


@pytest.mark.ecosystem
async def test_marketplace_search(ecosystem_manager):
    """Test marketplace search functionality"""
    # Create some test items first
    await ecosystem_manager.marketplace_manager.register_marketplace_item(
        name="Test Plugin 1",
        description="Description 1",
        category=MarketplaceCategory.PLUGINS,
        version="1.0.0",
        author="Test Author",
        author_id="test_user",
        tags=["test", "plugin"],
        file_content=b"test content"
    )

    await ecosystem_manager.marketplace_manager.register_marketplace_item(
        name="Test Integration",
        description="Description 2",
        category=MarketplaceCategory.INTEGRATIONS,
        version="1.0.0",
        author="Test Author",
        author_id="test_user",
        tags=["test", "integration"],
        file_content=b"test content",
        pricing_model="paid"
    )

    # Test search by category
    plugin_items = await ecosystem_manager.marketplace_manager.search_marketplace_items(
        category=MarketplaceCategory.PLUGINS
    )
    assert len(plugin_items) >= 1, "Should find plugin items"

    # Test search by tag
    tagged_items = await ecosystem_manager.marketplace_manager.search_marketplace_items(
        tags=["test"]
    )
    assert len(tagged_items) >= 1, "Should find tagged items"

    # Test text search
    search_results = await ecosystem_manager.marketplace_manager.search_marketplace_items(
        query="Test"
    )
    assert len(search_results) >= 1, "Should find search results"


@pytest.mark.ecosystem
async def test_community_contributors(ecosystem_manager):
    """Test community contributor management"""
    # Register contributors
    contributor1 = await ecosystem_manager.community_manager.register_contributor(
        username="alice",
        email="alice@example.com",
        bio="Software developer interested in AI",
        github_username="alice-dev"
    )

    contributor2 = await ecosystem_manager.community_manager.register_contributor(
        username="bob",
        email="bob@example.com",
        bio="Data scientist with ML expertise",
        github_username="bob-ml"
    )

    assert contributor1.contributor_id is not None, "Contributor 1 should have ID"
    assert contributor1.username == "alice", "Username should match"
    assert contributor1.contributor_id == contributor2.contributor_id - 1, "IDs should be unique"

    # Test contributor statistics
    stats = await ecosystem_manager.community_manager.get_contributor_stats(contributor1.contributor_id)
    assert "contributor_id" in stats, "Should have contributor ID"
    assert "username" in stats, "Should have username"
    assert stats["issues_created"] == 0, "Should have no issues created yet"


@pytest.mark.ecosystem
async def test_community_issues(ecosystem_manager):
    """Test community issue management"""
    # Register contributor first
    contributor = await ecosystem_manager.community_manager.register_contributor(
        username="charlie",
        email="charlie@example.com"
    )

    # Create issue
    issue = await ecosystem_manager.community_manager.create_issue(
        title="Feature Request: Dark Mode Support",
        description="Add dark mode support to the user interface",
        category="feature_request",
        priority="medium",
        author_id=contributor.contributor_id,
        tags=["ui", "dark_mode", "feature"]
    )

    assert issue.issue_id is not None, "Issue should have ID"
    assert issue.title == "Feature Request: Dark Mode Support", "Title should match"
    assert issue.status == "open", "Issue should be open"
    assert issue.author_id == contributor.contributor_id, "Author should match"

    # Test comment addition
    comment_added = await ecosystem_manager.community_manager.add_comment(
        issue.issue_id,
        author_id=contributor.contributor_id,
        content="This would be a valuable addition to the UI"
    )
    assert comment_added is True, "Comment should be added"

    # Check comment was added
    updated_issue = ecosystem_manager.community_manager.get_contributor_stats(contributor.contributor_id)
    # Implementation would need to be added to check comments
    # For now, just verify the comment was added successfully


@pytest.mark.ecosystem
async def test_integrations(ecosystem_manager):
    """Test integration management"""
    # Register integration
    integration = await ecosystem_manager.integration_manager.register_integration(
        name="GitHub Integration",
        description="Connect with GitHub repositories",
        integration_type=IntegrationType.WEBHOOK,
        version="1.0.0",
        configuration_schema={
            "type": "object",
            "properties": {
                "repo_url": {"type": "string"},
                "access_token": {"type": "string"},
                "webhook_secret": {"type": "string"}
            },
            "required": ["repo_url", "access_token"]
        },
        authentication={
            "type": "oauth",
            "provider": "github"
        },
        endpoints={
            "api": "https://api.github.com",
            "webhook": "https://hooks.slack.com/services/T00000000/B00000000"
        }
    )

    assert integration.integration_id is not None, "Integration should have ID"
    assert integration.name == "GitHub Integration", "Name should match"
    assert integration.integration_type == IntegrationType.WEBHOOK, "Type should match"

    # Test integration configuration
    config = {
        "repo_url": "https://github.com/user/repo",
        "access_token": "github_pat_token"
    }

    config_success = await ecosystem_manager.integration_manager.configure_integration(
        integration.integration_id,
        config
    )
    assert config_success is True, "Configuration should succeed"

    # Test webhook creation
    webhook_url = await ecosystem_manager.integration_manager.create_webhook_endpoint(integration.integration_id)
    assert webhook_url is not None, "Webhook URL should be created"
    assert webhook_url.startswith("/webhooks/"), "URL should start with /webhooks/"


@pytest.mark.ecosystem
async def test_api_keys(ecosystem_manager):
    """Test API key management"""
    # Create API key
    api_key = await ecosystem_manager.api_key_manager.create_api_key(
        user_id="user_001",
        permissions=["read", "write"],
        rate_limit=5000,
        expires_days=30
    )

    assert api_key.key_id is not None, "API key should have ID"
    assert api_key.user_id == "user_001", "User ID should match"
    assert len(api_key.permissions) == 2, "Should have 2 permissions"
    assert api_key.rate_limit == 5000, "Rate limit should match"
    assert api_key.expires_at is not None, "Expiration should be set"

    # Test API key validation
    # Note: In a real implementation, we'd need the actual key string
    # For this test, we'll just validate the hash
    validated_key = await ecosystem_manager.api_key_manager.validate_api_key(
        api_key.key_hash
    )
    assert validated_key is not None, "API key should be valid"
    assert validated_key.user_id == "user_001", "User ID should match"

    # Test API key revocation
    revoked = await ecosystem_manager.api_key_manager.revoke_api_key(api_key.key_hash)
    assert revoked is True, "API key should be revoked"


@pytest.mark.ecosystem
async def test_ecosystem_overview(ecosystem_manager):
    """Test ecosystem overview generation"""
    overview = await ecosystem_manager.get_ecosystem_overview()

    assert "statistics" in overview, "Should have statistics"
    assert "marketplace" in overview, "Should have marketplace section"
    assert "plugins" in overview, "Should have plugins section"
    assert "community" in overview, "Should have community section"
    assert "integrations" in overview, "Se integrations section"
    assert "api_keys" in overview, "Should have API keys section"

    # Check marketplace stats
    marketplace_stats = overview["marketplace"]
    assert "total_items" in marketplace_stats, "Should have total items count"
    assert "categories" in marketplace_stats, "Should have categories breakdown"

    # Check plugins stats
    plugins_stats = overview["plugins"]
    assert "total_installed" in plugins_stats, "Should have total installed count"
    assert "types" in plugins_stats, "Should have plugin types breakdown"

    # Check community stats
    community_stats = overview["community"]
    assert "total_contributors" in community_stats, "Should have total contributors count"
    assert "total_issues" in community_stats, "Should have total issues count"


if __name__ == "__main__":
    # Run ecosystem development demonstration
    print("=" * 70)
    print("ECOSYSTEM DEVELOPMENT DEMONSTRATION")
    print("=" * 70)

    async def main():
        print("\n--- Initializing Ecosystem Components ---")

        # Initialize all managers
        ecosystem = EcosystemManager(
            marketplace_path="./marketplace_data",
            plugins_path="./plugins_data",
            community_path="./community_data",
            integrations_path="./integrations_data",
            api_keys_path="./api_keys_data"
        )

        print(" Marketplace manager initialized")
        print(" Plugin manager initialized")
        print(" Community manager initialized")
        register_community_contributors(community_manager)
        print(" Integration manager initialized")
        print(" API key manager initialized")

        print(f"\n--- Setting Up Community ---")

        # Register community contributors
        contributors_to_register = [
            {
                "username": "alice_chen",
                "email": "alice@enhanced-cognee.com",
                "bio": "Senior AI Engineer with 10 years of experience in multi-agent systems. Passionate about building scalable AI solutions.",
                "github_username": "alice-ai-eng"
            },
            {
                "username": "bob_wilson",
                "email": "bob@techcorp.com",
                "bio": "Data scientist specializing in machine learning and deep learning. Love working with large language models and distributed systems.",
                "github_username": "bob-data-scientist"
            },
            {
                "username": "carolyn_davis",
                "email": "carolyn@startup.com",
                "bio": "Product manager with expertise in B2B SaaS. Focused on user experience and go-to-market strategies.",
                "github_username": "carolyn-pm"
            },
            {
                "username": "david_miller",
                "email": "david@enterprise.com",
                "bio": "DevOps engineer with extensive experience in Kubernetes and cloud-native architectures.",
                "github_username": "david-devops"
            }
        ]

        registered_contributors = []
        for contributor_data in contributors_to_register:
            contributor = await ecosystem.community_manager.register_contributor(
                username=contributor_data["username"],
                email=contributor_data["email"],
                bio=contributor_data["bio"],
                github_username=contributor_data["github_username"]
            )
            registered_contributors.append(contributor)
            print(f"    Registered contributor: {contributor.username} ({contributor.email})")

        print(f"    Total Contributors: {len(registered_contributors)}")

        print(f"\n--- Creating Marketplace Items ---")

        # Create sample marketplace items
        marketplace_items = [
            {
                "name": "Advanced Trading Bot Template",
                "description": "Pre-configured trading bot with RSI, MACD, and machine learning strategies",
                "category": MarketplaceCategory.TEMPLATES,
                "version": "1.5.0",
                "author": "Trading Solutions Inc",
                "author_id": registered_contributors[0].contributor_id,
                "tags": ["trading", "bot", "rsi", "macd", "template"],
                "pricing_model": "freemium"
            },
            {
                "name": "Database Connection Pool",
                "description": "High-performance database connection pooling for Enhanced Cognee",
                "category": MarketplaceCategory.PLUGINS,
                "version": "2.0.0",
                "author": "Database Experts",
                "author_id": registered_contributors[1].contributor_id,
                "tags": ["database", "connection", "pooling", "performance"],
                "pricing_model": "free"
            },
            {
                "name": "Slack Integration",
                "description": "Real-time messaging and notifications via Slack",
                "category": MarketplaceCategory.INTEGRATIONS,
                "version": "1.2.0",
                "author": "Communication Tools Ltd",
                "author_id": registered_contributors[2].contributor_id,
                "tags": ["slack", "messaging", "notifications", "integrations"],
                "pricing_model": "paid"
            },
            {
                "name": "ML Model Library",
                "description": "Pre-trained models for various AI and ML tasks",
                "category": MarketplaceCategory.MODELS,
                "version": "3.0.0",
                "author": "AI Research Lab",
                "author_id": registered_contributors[3].contributor_id,
                "tags": ["ml", "models", "pretrained", "ai"],
                "pricing_model": "enterprise"
            },
            {
                "name": "Analytics Dashboard",
                "description": "Real-time analytics dashboard with custom metrics",
                "category": MarketplaceCategory.VISUALIZATION,
                "version": "4.1.0",
                "author": "DataViz Pro",
                "author_id": registered_contributors[1].contributor_id,
                "tags": ["analytics", "dashboard", "metrics", "visualization"],
                "pricing_model": "freemium"
            }
        ]

        created_items = []
        for item_data in marketplace_items:
            # Create mock file content
            file_content = f"""
# Enhanced Cognee {item_data['name']}
Version: {item_data['version']}
Author: {item_data['author']}
Description: {item_data['description']}
Tags: {', '.join(item_data['tags'])}
License: MIT
Pricing: {item_data['pricing_model']}

# This is a demo marketplace item for Enhanced Cognee ecosystem.
"""

            item = await ecosystem.marketplace_manager.register_marketplace_item(
                name=item_data["name"],
                description=item_data["description"],
                category=item_data["category"],
                version=item_data["version"],
                author=item_data["author"],
                author_id=item_data["author_id"],
                tags=item_data["tags"],
                file_content=file_content.encode(),
                pricing_model=item_data["pricing_model"]
            )

            created_items.append(item)
            print(f"    Created: {item_data['name']} ({item_data['category'].value})")

        print(f"    Total Items: {len(created_items)}")

        print(f"\n--- Installing Plugins ---")

        # Create sample plugins
        plugin_configs = [
            {
                "plugin_id": "sentiment_analysis_plugin",
                "name": "Advanced Sentiment Analysis",
                "description": "Real-time sentiment analysis for trading decisions",
                "plugin_type": PluginType.ANALYTICS,
                "version": "1.0.0",
                "entry_point": "sentiment_analysis.py",
                "configuration_schema": {
                    "type": "object",
                    "properties": {
                        "model_path": {"type": "string"},
                        "confidence_threshold": {"type": "number", "minimum": 0.5},
                        "update_frequency": {"type": "number", "minimum": 60}
                    },
                    "required": ["model_path"]
                },
                "dependencies": ["numpy", "scikit-learn", "nltk"],
                "permissions": ["read_data", "write_data"],
                "metadata": {
                    "performance_impact": "low",
                    "resource_usage": "medium"
                }
            },
            {
                "plugin_id": "notification_system",
                "name": "Advanced Notification System",
                "description": "Multi-channel notification system with smart routing",
                "plugin_type": PluginType.NOTIFICATION,
                "version": "2.1.0",
                "entry_point": "notifications.py",
                "configuration_schema": {
                    "type": "object",
                    "properties": {
                        "channels": {"type": "array", "items": {"type": "string"}},
                        "default_channel": {"type": "string"},
                        "retry_attempts": {"type": "number", "minimum": 3}
                    },
                    "required": ["channels"]
                },
                "dependencies": ["aiohttp", "smtplib"],
                "permissions": ["send_notifications"],
                "metadata": {
                    "channels_supported": ["email", "slack", "webhook"],
                    "performance_impact": "medium"
                }
            },
            {
                "plugin_id": "security_scanner",
                "name": "Security Vulnerability Scanner",
                "description": "Automated security scanning for Enhanced Cognee",
                "plugin_type": PluginType.SECURITY,
                "version": "3.0.0",
                "entry_point": "security_scanner.py",
                "configuration_schema": {
                    "type": "object",
                    "properties": {
                        "scan_frequency": {"type": "number", "minimum": 86400},
                        "scan_types": {"type": "array", "items": {"type": "string"}},
                        "alert_threshold": {"type": "number", "minimum": 1}
                    },
                    "required": ["scan_frequency", "scan_types"]
                },
                "dependencies": ["requests", "bandit", "safety"],
                "permissions": ["scan_results", "security_logs"],
                "metadata": {
                    "scan_engines": ["bandit", "safety", "semgrep"],
                    "severity_levels": ["low", "medium", "high", "critical"]
                }
            }
        ]

        for plugin_config in plugin_configs:
            plugin = Plugin(
                plugin_id=plugin_config["plugin_id"],
                name=plugin_config["name"],
                description=plugin_config["description"],
                plugin_type=plugin_config["plugin_type"],
                version=plugin_config["version"],
                entry_point=plugin_config["entry_point"],
                configuration_schema=plugin_config["configuration_schema"],
                dependencies=plugin_config["dependencies"],
                permissions=plugin_config["permissions"],
                metadata=plugin_config["metadata"]
            )
            ecosystem.plugin_manager.plugins[plugin.plugin_id] = plugin
            print(f"    Registered: {plugin.name} ({plugin.plugin_type.value})")

        print(f"    Total Plugins: {len(ecosystem_manager.plugin_manager.plugins)}")

        print(f"\n--- Setting Up Integrations ---")

        # Create sample integrations
        integration_configs = [
            {
                "name": "Grafana Monitoring",
                "description": "Connect Enhanced Cognee metrics with Grafana",
                "integration_type": IntegrationType.REST_API,
                "version": "1.0.0",
                "configuration_schema": {
                    "type": "object",
                    "properties": {
                        "grafana_url": {"type": "string"},
                        "api_key": {"type": "string"},
                        "dashboard_ids": {"type": "array", "items": {"type": "string"}}
                    },
                    "required": ["grafana_url", "api_key"]
                },
                "authentication": {
                    "type": "api_key",
                    "provider": "grafana"
                },
                "endpoints": {
                    "api": "https://grafana.com/api",
                    "dashboards": "https://grafana.com/api/dashboards"
                }
            },
            {
                "name": "Prometheus Metrics",
                "description": "Prometheus metrics collection and monitoring",
                "integration_type": IntegrationType.MONITORING,
                "version": "2.1.0",
                "configuration_schema": {
                    "type": "object",
                    "properties": {
                        "prometheus_url": {"type": "string"},
                        "metrics_endpoint": {"type": "string"},
                        "scrape_interval": {"type": "number", "minimum": 15}
                    },
                    "required": ["prometheus_url", "metrics_endpoint"]
                },
                "authentication": {
                    "type": "basic_auth"
                },
                "endpoints": {
                    "metrics": "http://prometheus:9090/metrics",
                    "query": "http://prometheus:9090/api/v1/query"
                }
            },
            {
                "name": "Elasticsearch Logging",
                "description": "Centralized logging with Elasticsearch",
                "integration_type": IntegrationType.DATABASE,
                "version": "2.0.0",
                "configuration_schema": {
                    "type": "object",
                    "properties": {
                        "elasticsearch_url": {"type": "string"},
                        "index_pattern": {"type": "string"},
                        "bulk_size": {"type": "number", "minimum": 100}
                    },
                    "required": ["elasticsearch_url", "index_pattern"]
                },
                "authentication": {
                    "type": "basic_auth"
                },
                "endpoints": {
                    "index": "http://elasticsearch:9200/{index_pattern}",
                    "search": "http://elasticsearch:9200/{index_pattern}/_search"
                }
            }
        ]

        created_integrations = []
        for integration_config in integration_configs:
            integration = await ecosystem.integration_manager.register_integration(
                name=integration_config["name"],
                description=integration_config["description"],
                integration_type=integration_config["integration_type"],
                version=integration_config["version"],
                configuration_schema=integration_config["configuration_schema"],
                authentication=integration_config["authentication"],
                endpoints=integration_config["endpoints"]
            )
            created_integrations.append(integration)
            print(f"    Created: {integration.name} ({integration.integration_type.value})")

        print(f"    Total Integrations: {len(created_integrations)}")

        print(f"\n--- Creating Community Issues and Discussions ---")

        # Create sample issues
        issue_data = [
            {
                "title": "Add Support for Gemini Pro API",
                "description": "Integration with Google's latest AI model for enhanced reasoning capabilities",
                "category": "feature_request",
                "priority": "high",
                "author_id": registered_contributors[0].contributor_id,
                "tags": ["gemini", "api", "ai", "feature"]
            },
            {
                "title": "Improve Documentation",
                "description": "Enhance technical documentation with more examples and tutorials",
                "category": "improvement",
                "priority": "medium",
                "author_id": registered_contributors[1].contributor_id,
                "tags": ["documentation", "tutorials", "examples"]
            },
            {
                "title": "Bug Report: Memory Leak in Agent Manager",
                "description": "Memory usage increases over time in multi-agent environments",
                "category": "bug_report",
                "priority": "high",
                "author_id": registered_contributors[3].contributor_id,
                "tags": ["bug", "memory", "performance", "agent"]
            }
        ]

        created_issues = []
        for issue_data in issue_data:
            issue = await ecosystem.community_manager.create_issue(
                title=issue_data["title"],
                description=issue_data["description"],
                category=issue_data["category"],
                priority=issue_data["priority"],
                author_id=issue_data["author_id"],
                tags=issue_data["tags"]
            )
            created_issues.append(issue)
            print(f"    Created: {issue.title} ({issue.category})")

        # Add comments to issues
        for issue in created_issues[:2]:
            await ecosystem.community_manager.add_comment(
                issue_id=issue.issue_id,
                author_id=registered_contributors[2].contributor_id,
                content="This looks like a valuable addition to the ecosystem!"
            )

        print(f"    Total Issues: {len(created_issues)}")
        print(f"    Comments Added: 2")

        print(f"\n--- Generating API Keys ---")

        # Create API keys for different use cases
        api_key_configs = [
            {
                "user_id": "service_account_001",
                "permissions": ["read", "write", "admin"],
                "rate_limit": 10000,
                "expires_days": 365,
                "description": "Service account for system operations"
            },
            {
                "user_id": "developer_001",
                "permissions": ["read", "write"],
                "rate_limit": 5000,
                "expires_days": 90,
                "description": "Developer API key for application access"
            },
            {
                "user_id": "partner_001",
                "permissions": ["read"],
                "rate_limit": 1000,
                "expires_days": 30,
                "description": "Partner API key for limited access"
            }
        ]

        created_api_keys = []
        for config in api_key_configs:
            api_key = await ecosystem.api_key_manager.create_api_key(
                user_id=config["user_id"],
                permissions=config["permissions"],
                rate_limit=config["rate_limit"],
                expires_days=config["expires_days"]
            )
            created_api_keys.append(api_key)
            print(f"    Created API key for {config['user_id']}")

        print(f"    Total API Keys: {len(created_api_keys)}")

        print(f"\n--- Generating Ecosystem Overview ---")

        overview = await ecosystem.get_ecosystem_overview()

        print(f" Ecosystem Overview:")
        print(f"   Total Marketplace Items: {overview['statistics']['total_marketplace_items']}")
        print(f"   Total Plugins: {overview['statistics']['total_plugins']}")
        print(f"   Total Integrations: {overview['statistics']['total_integrations']}")
        print(f"   Total Contributors: {overview['statistics']['total_contributors']}")
        print(f"   Total Issues: {overview['statistics']['total_issues']}")
        print(f"   Active API Keys: {overview['statistics']['active_api_keys']}")

        # Marketplace breakdown
        marketplace_stats = overview["marketplace"]
        print(f"\n Marketplace Breakdown:")
        print(f"   Total Items: {marketplace_stats['total_items']}")
        print(f"   Categories: {list(marketplace_stats['categories'].keys())}")
        print(f"   Featured: {marketplace_stats['featured_items']}")
        print(f"   Verified: {marketplace_stats['verified_items']}")

        # Plugin breakdown
        plugins_stats = overview["plugins"]
        print(f"\n Plugin Breakdown:")
        print(f"   Installed: {plugins_stats['total_installed']}")
        print(f"   Active: {plugins_stats['active_plugins']}")
        print(f"   Types: {list(plugins_stats['types'].keys())}")

        # Community statistics
        community_stats = overview["community"]
        print(f"\n Community Statistics:")
        print(f"   Contributors: {community_stats['total_contributors']}")
        print(f"   Issues: {community_stats['total_issues']}")
        print(f"   Open Issues: {community_stats['open_issues']}")
        print(f"   Resolved Issues: {community_stats['resolved_issues']}")

        print(f"\n--- Real-Time Monitoring Simulation ---")

        # Simulate real-time metrics
        print(" Simulating ecosystem metrics...")

        for i in range(5):
            # Simulate download count updates
            random_item = ecosystem.marketplace_manager.marketplace_items[
                list(ecosystem.marketplace_manager.marketplace_items.keys())[i % len(ecosystem_manager.marketplace_items)]
            ]
            await ecosystem.marketplace_manager.update_download_count(random_item.item_id)

            # Simulate rating updates
            random_item = ecosystem.marketplace_manager.marketplace_items[
                list(ecosystem_manager.marketplace_manager.marketplace_items.keys())[i % len(ecosystem_manager.marketplace_items)]
            ]
            new_rating = 3.0 + np.random.random() * 2.0  # 3.0-5.0 range
            random_item.rating = (random_item.rating * 4 + new_rating) / 5
            random_item.updated_at = datetime.now(timezone.utc)
            ecosystem.marketplace_manager._save_data()

        total_downloads = sum(item.download_count for item in ecosystem.marketplace_marketplace_items.values())
        avg_rating = np.mean([item.rating for item in ecosystem.marketplace_marketplace_items.values()]) if ecosystem.marketplace_manager.marketplace_items else 0

        print(f"    Marketplace Activity:")
        print(f"      Total Downloads: {total_downloads}")
        print(f"      Average Rating: {avg_rating:.2f}")

        await asyncio.sleep(0.1)  # Simulate processing time

        print(f"\n--- Generating Reports ---")

        # Generate marketplace analytics report
        marketplace_report = {
            "generated_at": datetime.now(timezone.utc).isoformat(),
            "period": "last_24h",
            "total_items": len(ecosystem_manager.marketplace_items),
            "downloads_24h": total_downloads,
            "avg_rating": avg_rating,
            "top_downloads": sorted(
                [(item.name, item.download_count) for item in ecosystem.marketplace_manager.marketplace_items.values()],
                key=lambda x: x[1],
                reverse=True
            )[:10],
            "categories": {}
        }

        # Category breakdown
        for category in MarketplaceCategory:
            category_items = [
                item for item in ecosystem.marketplace_marketplace_items.values()
                if item.category == category
            ]
            if category_items:
                marketplace_report["categories"][category.value] = {
                    "count": len(category_items),
                    "downloads": sum(item.download_count for item in category_items),
                    "avg_rating": np.mean([item.rating for item in category_items]) if category_items else 0
                }

        # Community activity report
        community_report = {
            "generated_at": datetime.now(timezone.utc).topoisoformat(),
            "total_contributors": len(ecosystem_manager.community_manager.contributors),
            "active_issues": len([i for i in ecosystem.community_manager.issues.values() if i.status == "open"]),
            "resolved_issues": len([i for i in ecosystem.community_manager.issues.values() if i.status == "resolved"]),
            "new_contributors_today": len([
                c for c in ecosystem.community_manager.contributors.values()
                if c.join_date >= datetime.now(timezone.utc) - timedelta(days=1)
            ]),
            "top_contributors": sorted(
                [(c.username, c.reputation) for c in ecosystem.community_manager.contributors.values()],
                key=lambda x: x[1],
                reverse=True
            )[:10]
        }

        print(f" Marketplace Report:")
        print(f"   Total Items: {marketplace_report['total_items']}")
        print(f"   Downloads (24h): {marketplace_report['downloads_24h']}")
        print(f"   Average Rating: {marketplace_report['avg_rating']:.2f}")
        print(f"      Top Downloads: {[f\"{name}: {count}\" for name, count in marketplace_report['top_downloads']]}")

        print(f"\n Community Report:")
        print(f"   Total Contributors: {community_report['total_contributors']}")
        print(f"   Active Issues: {community_report['active_issues']}")
        print(f"      Resolved Issues: {community_report['resolved_issues']}")
        print(f"      New Contributors (24h): {community_report['new_contributors_today']}")
        print(f"      Top Contributors: {[f\"{name}: {rep}\" for name, rep in community_report['top_contributors']}")

        # Save reports
        reports_dir = Path("./reports")
        reports_dir.mkdir(exist_ok=True)

        with open(reports_dir / "marketplace_report.json", 'w') as f:
            json.dump(marketplace_report, f, indent=2)

        with open(reports_dir / "community_report.json", 'w') as f:
            json.dump(community_report, f, indent=2)

        print(f"    Reports saved to ./reports/")

        print(f"\n--- Integration Testing ---")

        # Test integrations
        for integration in created_integrations[:2]:
            print(f"    Testing: {integration.name}")
            test_result = await ecosystem.integration_manager.test_integration(integration.integration_id)

            test_summary = " All Tests Passed" if test_result["success"] else " Some Tests Failed"
            print(f"      {test_summary}")

            if test_result["tests"]:
                print(f"      Tests Executed: {len(test_result['tests'])}")
                for test in test_result["tests"][:3]:
                    status = "" if test["status"] == "success" else ""
                    print(f"         {status} {test['endpoint']} ({test.get('response_time_ms', 'N/A')}ms)")

        print(f"\n--- API Key Testing ---")

        # Test API key validation
        for api_key in created_api_keys[:2]:
            print(f"    Testing API key for user {api_key.user_id}")
            validated_key = await ecosystem.api_key_manager.validate_api_key(api_key.key_hash)
            validation_status = " Valid" if validated_key else " Invalid"
            print(f"      Status: {validation_status}")

        print(f"\n--- Demonstrating Webhook Handling ---")

        # Simulate webhook handling
        for integration in created_integrations:
            if integration.webhook_urls:
                webhook_url = integration.webhook_url[0]
                print(f"    Setting up webhook: {webhook_url}")

                # Simulate webhook call
                webhook_data = {
                    "event": "test",
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                    "data": {"test": True}
                }

                # In production, this would make actual webhook calls
                print(f"       Simulating webhook call to {webhook_url}")
                print(f"      Data: {json.dumps(webhook_data)[:100]}...")

        print(f"\n--- Ecosystem Features Demonstration ---")

        print(f" Advanced Ecosystem Features:")
        features = [
            " Complete Marketplace with Categorized Items",
            " Plugin System with Hot Loading",
            " Third-Party Integration Framework",
            " Community Contribution Platform",
            " API Management with Fine-Grained Access Control",
            " Real-Time Analytics and Reporting",
            " Webhook Support for Event-Driven Architecture",
            " Version Compatibility Management",
            " Security and Compliance Monitoring",
            " Automated Testing and Validation",
            " Configuration Management and Templates",
            " Documentation and Knowledge Base",
            " Support Ticketing and Issue Tracking"
            " Automated Backup and Recovery"
            " Performance Monitoring and Optimization"
            " Custom Development Environment Support"
        ]

        for feature in features:
            print(f"   {feature}")

        print(f"\n" + "=" * 70)
        print("ECOSYSTEM DEVELOPMENT DEMONSTRATION COMPLETED")
        print("=" * 70)
        print("\n Key Achievements:")
        print("    Complete marketplace with multiple categories")
        print("    Extensible plugin system with hot loading")
        print("    Comprehensive integration framework with webhook support")
        print("    Community platform with contributions and issue tracking")
           API key management with role-based access control")
        print("    Real-time analytics and comprehensive reporting")
        print("    Automated testing and validation capabilities")
        print("\n Business Benefits:")
        print("    Monetization through marketplace sales and enterprise features")
        print("    Extensibility through third-party integrations")
        print("    Community-driven innovation and feature development")
        print("    Centralized API access management for ecosystem partners")
        print("    Real-time monitoring of ecosystem health and usage")
        print("    Automated quality assurance and compliance validation")

    asyncio.run(main())